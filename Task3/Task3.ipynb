{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def image_show(image, window_name= 'image'):\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def blur_and_laplacian(image, ksize):\n",
    "    image_gaussian = cv2.GaussianBlur(image,(ksize,ksize),0)\n",
    "    #image_show(image_gaussian)\n",
    "    # [laplacian]\n",
    "    # Apply Laplace function\n",
    "    dst = cv2.Laplacian(image_gaussian, cv2.CV_64F, ksize)\n",
    "    abs_dst = cv2.convertScaleAbs(dst)\n",
    "    return abs_dst\n",
    "def template_laplacian(image, ksize):\n",
    "    dst = cv2.Laplacian(image, cv2.CV_64F, ksize)\n",
    "    abs_dst = cv2.convertScaleAbs(dst)\n",
    "    image_show(abs_dst)\n",
    "    return abs_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import match_template\n",
    "\n",
    "def match_template_opencv_ccoeff_normed(image_gray, temp_gray):    \n",
    "    \n",
    "    img_gray = image_gray\n",
    "    template = temp_gray\n",
    "\n",
    "    w, h = template.shape[::-1]\n",
    "    res = cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)\n",
    "    cv.normalize( res, res, 0, 1, cv.NORM_MINMAX, -1 )\n",
    "    threshold = 0.98\n",
    "    loc = np.where( res >= threshold)\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        #cv.rectangle(image_gray, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "        cv.rectangle(image_gray, pt, (pt[0] + w, pt[1] + h), (255,255,255), 2)\n",
    "        #rectangle can be made on original image as well\n",
    "    image_show(image_gray)\n",
    "    return image_gray\n",
    "\n",
    "def skimage_template_matching(image, coin):\n",
    "    #image = data.coins()\n",
    "    #coin = image[170:220, 75:130]\n",
    "    \n",
    "    hcoin, wcoin = coin.shape\n",
    "    w, h = coin.shape\n",
    "    result = match_template(image, coin)\n",
    "    cv.normalize( result, result, 0, 1, cv.NORM_MINMAX, -1 )\n",
    "    threshold = 0.98\n",
    "    loc = np.where( result >= threshold)\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        #cv.rectangle(image_gray, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "        cv.rectangle(image, pt, (pt[0] + w, pt[1] + h), (255,255,255), 2)\n",
    "        #rectangle can be made on original image as well\n",
    "    ij = np.unravel_index(np.argmax(result), result.shape)\n",
    "    x, y = ij[::-1]\n",
    "    \n",
    "    image = cv2.rectangle(image, (x, y), (x+wcoin, y+hcoin), (255,0,0), 2)\n",
    "\n",
    "\n",
    "    image_show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2 as cv\n",
    "ksize = 7\n",
    "\n",
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/*.jpg\")]\n",
    "#template = cv2.imread('task3/template15.png',cv2.IMREAD_GRAYSCALE)\n",
    "template = cv2.imread('task3/template17.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "b_l_template = template_laplacian(template, ksize)\n",
    "\n",
    "for image in positive_images:\n",
    "    b_l_image = template_laplacian(image, ksize)\n",
    "    match_template_opencv_ccoeff_normed(b_l_image, b_l_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-a5e94fc06b51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mb_l_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemplate_laplacian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mskimage_template_matching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_l_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_l_template\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-449e6b8c82dc>\u001b[0m in \u001b[0;36mskimage_template_matching\u001b[1;34m(image, coin)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#cv.rectangle(image_gray, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m#rectangle can be made on original image as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "ksize = 7\n",
    "\n",
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/*.jpg\")]\n",
    "#template = cv2.imread('task3/template15.png',cv2.IMREAD_GRAYSCALE)\n",
    "template = cv2.imread('task3/template17.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "b_l_template = template_laplacian(template, ksize)\n",
    "\n",
    "for image in positive_images:\n",
    "    b_l_image = template_laplacian(image, ksize)\n",
    "    skimage_template_matching(b_l_image, b_l_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template3.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for image in positive_images:\n",
    "    match_template_opencv_ccoeff_normed(image, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template4.png',cv2.IMREAD_GRAYSCALE)\n",
    "b_l_template = blur_and_laplacian(template, ksize)\n",
    "\n",
    "for image in positive_images:\n",
    "    b_l_image = blur_and_laplacian(image, ksize)\n",
    "    match_template_opencv_ccoeff_normed(b_l_image, b_l_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template4.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for image in positive_images:\n",
    "    skimage_template_matching(image, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template4.png',cv2.IMREAD_GRAYSCALE)\n",
    "b_l_template = blur_and_laplacian(template, ksize)\n",
    "\n",
    "for image in positive_images:\n",
    "    b_l_image = blur_and_laplacian(image, ksize)\n",
    "    skimage_template_matching(b_l_image, b_l_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final approach\n",
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template3.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for image in positive_images:\n",
    "    skimage_template_matching(image, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template3.png',cv2.IMREAD_GRAYSCALE)\n",
    "b_l_template = template_laplacian(template, ksize)\n",
    "\n",
    "for image in positive_images:\n",
    "    b_l_image = blur_and_laplacian(image, ksize)\n",
    "    skimage_template_matching(b_l_image, b_l_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template1.png',cv2.IMREAD_GRAYSCALE)\n",
    "b_l_template = blur_and_laplacian(template, ksize)\n",
    "\n",
    "for image in positive_images:\n",
    "    b_l_image = blur_and_laplacian(image, ksize)\n",
    "    skimage_template_matching(b_l_image, b_l_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================= #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template16.png',cv2.IMREAD_GRAYSCALE)\n",
    "b_l_template = template_laplacian(template, ksize)\n",
    "\n",
    "for image in positive_images:\n",
    "    b_l_image = blur_and_laplacian(image, ksize)\n",
    "    match_template_opencv_ccoeff_normed(b_l_image, b_l_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template14.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for image in positive_images:\n",
    "    \n",
    "    match_template_opencv_ccoeff_normed(image, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_template_opencv_ccoeff_normed(image_gray, temp_gray)\n",
    "#call with different templates to check\n",
    "#call with binary image\n",
    "#call with laplacian and different templates\n",
    "#blur_and_laplacian==> send grayscale image\n",
    "ksize = 3\n",
    "image =  cv2.imread('task3/check/pos_1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#template = cv2.imread('task3/template3.png',cv2.IMREAD_GRAYSCALE)  #good matches\n",
    "template = cv2.imread('task3/template4.png',cv2.IMREAD_GRAYSCALE)\n",
    "image_show(image)\n",
    "image_show(template)\n",
    "\n",
    "b_l_image = blur_and_laplacian(image, ksize)\n",
    "image_show(b_l_image)\n",
    "\n",
    "b_l_template = blur_and_laplacian(template, ksize)\n",
    "image_show(b_l_template)\n",
    "\n",
    "\n",
    "for image in pos3:\n",
    "    b_l_image = blur_and_laplacian(image, ksize)\n",
    "    skimage_template_matching(b_l_image, b_l_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import cv2 as cv\n",
    "\n",
    "## [global_variables]\n",
    "use_mask = False\n",
    "img = None\n",
    "templ = None\n",
    "mask = None\n",
    "image_window = \"Source Image\"\n",
    "result_window = \"Result window\"\n",
    "\n",
    "match_method = 0\n",
    "max_Trackbar = 5\n",
    "## [global_variables]\n",
    "\n",
    "\n",
    "#img = cv.imread('task3/pos/pos_1.jpg', cv.IMREAD_COLOR)\n",
    "#templ = cv.imread('task3/template3.png', cv.IMREAD_COLOR)\n",
    "templ = b_l_template\n",
    "img = b_l_image\n",
    "\n",
    "\n",
    "\n",
    "if ((img is None) or (templ is None) or (use_mask and (mask is None))):\n",
    "    print('Can\\'t read one of the images')\n",
    "## [load_image]\n",
    "\n",
    "## [create_windows]\n",
    "cv.namedWindow( image_window, cv.WINDOW_AUTOSIZE )\n",
    "cv.namedWindow( result_window, cv.WINDOW_AUTOSIZE )\n",
    "## [create_windows]\n",
    "\n",
    "## [create_trackbar]\n",
    "trackbar_label = 'Method: \\n 0: SQDIFF \\n 1: SQDIFF NORMED \\n 2: TM CCORR \\n 3: TM CCORR NORMED \\n 4: TM COEFF \\n 5: TM COEFF NORMED'\n",
    "cv.createTrackbar( trackbar_label, image_window, match_method, max_Trackbar, MatchingMethod )\n",
    "## [create_trackbar]\n",
    "\n",
    "MatchingMethod(match_method)\n",
    "\n",
    "## [wait_key]\n",
    "cv.waitKey(0)\n",
    "## [wait_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template matching with grayscale\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "w, h = template.shape[::-1]\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "\n",
    "pos = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in glob.glob(\"task3/pos/*.jpg\")]\n",
    "template = cv2.imread('task3/template4.png',cv2.IMREAD_GRAYSCALE)\n",
    "for image in pos:\n",
    "    img2 = image.copy()\n",
    "    for meth in methods:\n",
    "        img = img2.copy()\n",
    "        method = eval(meth)\n",
    "        # Apply template Matching\n",
    "        res = cv2.matchTemplate(img,template,method)\n",
    "        cv.normalize( res, res, 0, 1, cv.NORM_MINMAX, -1 )\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        cv.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "\n",
    "        #image_show(res)\n",
    "        image_show(img)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
